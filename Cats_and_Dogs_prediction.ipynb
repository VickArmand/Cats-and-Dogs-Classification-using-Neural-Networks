{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40042242",
   "metadata": {
    "id": "40042242"
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "import cv2\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,BatchNormalization, Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f9a263",
   "metadata": {
    "id": "c4f9a263"
   },
   "outputs": [],
   "source": [
    "# import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49ee35",
   "metadata": {
    "id": "1a49ee35"
   },
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a54dfb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a54dfb0",
    "outputId": "642c8be6-c9fb-47e4-c4e4-e546967470dd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24eca5c3",
   "metadata": {
    "id": "24eca5c3"
   },
   "outputs": [],
   "source": [
    "categories=['Cat','Dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Cs8HnhRbGAXo",
   "metadata": {
    "id": "Cs8HnhRbGAXo"
   },
   "outputs": [],
   "source": [
    "# imgdirectory='/content/drive/My Drive/Colab Notebooks/Cats and Dogs/'\n",
    "imgdirectory='F:\\TSUNAMIIPRAC2\\python &ml\\datasets2\\cats and dogs2\\PetImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c37fa5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c37fa5f",
    "outputId": "23348de5-df34-41cb-aa9a-e611dc93fc79"
   },
   "outputs": [],
   "source": [
    "UNIFORM_IMG_SIZE=100\n",
    "data=[]\n",
    "for category in categories:\n",
    "    folder=os.path.join(imgdirectory,category)\n",
    "#     print(folder)\n",
    "    label= categories.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path=os.path.join(folder,img)\n",
    "        img_arr=cv2.imread(img_path)\n",
    "#         print(img_path,type(img_arr))\n",
    "        if(type(img_arr)==type(None)):\n",
    "            print(img_path,type(img_arr))\n",
    "            os.remove(img_path)\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "# Since the images are different sizes we need to transform them into an uniform size\n",
    "            img_arr=cv2.resize(img_arr,(UNIFORM_IMG_SIZE,UNIFORM_IMG_SIZE))\n",
    "#         Reading all images into array\n",
    "#         plt.imshow(img_arr)\n",
    "        \n",
    "            data.append([img_arr,label])\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d736520",
   "metadata": {
    "id": "4d736520"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c1df74",
   "metadata": {
    "id": "b6c1df74"
   },
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae8f677",
   "metadata": {
    "id": "bae8f677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[170, 179, 243],\n",
       "         [162, 179, 242],\n",
       "         [167, 182, 245],\n",
       "         ...,\n",
       "         [179, 204, 254],\n",
       "         [183, 204, 255],\n",
       "         [183, 204, 254]],\n",
       " \n",
       "        [[172, 182, 246],\n",
       "         [165, 183, 246],\n",
       "         [168, 185, 248],\n",
       "         ...,\n",
       "         [181, 206, 255],\n",
       "         [184, 205, 255],\n",
       "         [182, 203, 254]],\n",
       " \n",
       "        [[171, 183, 247],\n",
       "         [163, 184, 246],\n",
       "         [169, 187, 250],\n",
       "         ...,\n",
       "         [180, 205, 255],\n",
       "         [184, 205, 255],\n",
       "         [183, 204, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[174, 187, 249],\n",
       "         [175, 190, 252],\n",
       "         [174, 192, 253],\n",
       "         ...,\n",
       "         [ 36,  61, 181],\n",
       "         [ 36,  59, 181],\n",
       "         [ 43,  65, 177]],\n",
       " \n",
       "        [[178, 189, 251],\n",
       "         [170, 189, 250],\n",
       "         [174, 189, 251],\n",
       "         ...,\n",
       "         [ 36,  62, 176],\n",
       "         [ 36,  65, 179],\n",
       "         [ 48,  69, 184]],\n",
       " \n",
       "        [[176, 185, 248],\n",
       "         [167, 186, 247],\n",
       "         [171, 189, 250],\n",
       "         ...,\n",
       "         [ 36,  63, 175],\n",
       "         [ 40,  71, 182],\n",
       "         [ 48,  69, 184]]], dtype=uint8),\n",
       " 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf05cf0",
   "metadata": {
    "id": "9cf05cf0"
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for features,labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073891a",
   "metadata": {
    "id": "c073891a"
   },
   "outputs": [],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7e1f5",
   "metadata": {
    "id": "90a7e1f5"
   },
   "outputs": [],
   "source": [
    "len(x)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946492a",
   "metadata": {
    "id": "c946492a"
   },
   "outputs": [],
   "source": [
    "# Lets save our processed images in the model to avoid the tendenciy of pre processing multiple times\n",
    "imagesmodel=pk.dump(x,open('images.pkl','wb'))\n",
    "labelsmodel=pk.dump(y,open('labels.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c799604",
   "metadata": {
    "id": "1c799604"
   },
   "source": [
    "# DATA MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccf97e",
   "metadata": {
    "id": "aeccf97e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=pk.load(open('images.pkl','rb'))\n",
    "y=pk.load(open('labels.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343d705",
   "metadata": {
    "id": "f343d705",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we are dividing by 255 because we want them to be in the same range\n",
    "for x2 in x:\n",
    "    if(type(x2)==type(None)):\n",
    "        pass\n",
    "    else:\n",
    "        x2=x2.astype('float32')/255\n",
    "     \n",
    "# x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640af29",
   "metadata": {
    "id": "a640af29"
   },
   "outputs": [],
   "source": [
    "# x2.shape\n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd657c",
   "metadata": {
    "id": "ddfd657c"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6716c",
   "metadata": {
    "id": "f6d6716c"
   },
   "outputs": [],
   "source": [
    "# Here we are adding the sequential model and adding convolution layers and max pooling \n",
    "model= Sequential()\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "# Flatten the result(Transforming the result in to a one dimension)\n",
    "model.add(Flatten())\n",
    "# Passing the result into the neural networks\n",
    "# One hidden layer of 128 neurons\n",
    "model.add(Dense(128,input_shape=x.shape[1:],activation='relu'))\n",
    "# Ooutput layer has 2 neurons since one is for the cat prediction while the other is for the dog prediction\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860e0a1",
   "metadata": {
    "id": "d860e0a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add loss functions and optimizers\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257fe15",
   "metadata": {
    "id": "b257fe15",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x,y,epochs=5,batch_size=64,validation_split=0.2)\n",
    "# 10% OF THE IMAGES WILL BE TAKEN FOR MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
